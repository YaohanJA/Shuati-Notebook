In this lesson, we're going to talk about a service which is mentioned quite a number of times, actually in the exam and that's Amazon Kinesis and when I say, it's a service I actually mean it's kind of a family of services, and we'll talk about the membership of that family in just a moment but at a high level Kinesis is all about ingesting large scale data and you need to remember that when we're talking about Amazon Web Services and we're talking about cloud large means really large and so we can broadly put this together into two categories. Either that we're bringing in large data sets from a few different sources, and so a good example of this would be video streaming. So video data there's usually it's usually quite high bandwidth compared with, say, just a simple sensor. So it's quite high bandwidth, and it's just continually streaming in. So if we have a fleet of 100 or 1000 different cameras, that are all streaming video data, then we might want to use Amazon Kinesis to help us marshal that, and to help us in a scalable way, bring that data into AWS. Another way of thinking about large data sets is not so much that the data itself is large, but think about internet of things. Imagine having 100,000 sensors deployed across your fleet of vehicles or a 1,000,000 internet connected fridges in homes of all of your customers, then there's lots and lots of data coming in, but in very, very small bits. So imagine lots of data points, but small data. Imagine IOT both of those use cases are perfect examples of where Amazon Kinesis comes into play. So we have these highly scalable endpoints for applications and systems to be able to send lots of data into AWS environment and there are four services which fit within this family of Amazon Kinesis doing just that or doing services around that job, and we have Amazon Kinesis video streams, Amazon Kinesis data streams, Amazon Kinesis data firehose, and then finally, Amazon Kinesis Data Analytics. So video streams. This one definitely gets talked about in this certification because we have remember Amazon Rekognition video and the way that we get video into Amazon Rekognition video is, well, one of two ways you can either pointed at an S3 bucket where some video objects really files are already stored as objects in that bucket, and that's if you want to analyze prerecorded video but if you want to analyze live video than your option is Amazon Kinesis video streams. So this allows us to be able to have a scalable endpoint to securely stream video from our connected devices out in the field directly into AWS, so that we can use it for analytics and importantly, of course, machine learning. We can also use it to be able to play back the video. So with Kinesis, it brings in all of that data and then stores it for a window of time and then our internal systems will be able to access that data, and that sliding window of data. So if we said that our playback window on our Kinesis video stream were set to seven days, then we'll be able to go to that Kinesis stream and pick out any part of the video from the last seven days and be able to stream it back to us in the same way we'll be able to train a machine learning algorithm and in the same way data would be available to our machine learning model to be able to make inference about that data from the last seven days. So Amazon Kinesis video streams are an important part and the important component if you wanted to do live video recognition or recognition video service. If you want to use that, then we have to plumb it in through the Kinesis video streams service. Now the next service in the family is Amazon Kinesis Data Streams and this is really your catchall. This is really the original service in the Kinesis family because this is all about creating a general endpoint to ingest just large quantities of data then what you do with it is largely up to you. So a primary use case and the original use case was that you would send this data into a fleet of EC2 instances that was running some software that you defined that would process that data, throw up data onto dashboards, do product recommendations on your website or something like that and Amazon EC2 was in the background, churning away on all of that originally and but now we've expanded out the number of services we can go to. Obviously, Lambda joins us. That's serverless compute environment just being able to churn through all that data by triggering Lambda every time a piece of data comes into Amazon Kinesis. We can also funnel the data through to EMR so elastic map reduce. If there's a lot of data coming in and you need to perform a lot of calculations on that data, then EMR is where you want to go and so Spark on EMR Spark is a term you're going to hear time and time again in machine learning in Amazon Web Services because Apache Spark is used by AWS as one of the family of machine learning tools that you can use across SageMaker and EMR and there is also the option. I've kind of gone through that list in reverse order, but there's also the option of using Kinesis Data Analytics, which is further down in the family tree, and we'll have a talk about that in just one second. Now Amazon Kinesis Data Streams. It's the original. It's highly configurable. You can kind of do whatever you want with it, but with all of that flexibility comes a little bit of complexity in terms of the ways that it is configured. What about if you want to do something a little bit simple? What about if you just want to do the same thing all the time? I just want to throw all the data that comes in into S2. Well, AWS have got us covered there with Amazon Kinesis Data Firehose. With Data Firehose, it's just a configuration step away from configuring the endpoints the Kinesis endpoint to be able to send data into one of a number of preset destinations and the top one on the list, of course, is S3. So we can just put all the data from all of our IOT devices and push it straight into S3 decouple our architecture and think about what to do later. If that's what we want to do, then Kinesis Data Firehose will do that for us. We can also send the data straight into Redshift. Redshift being Amazon Web Services data warehouse solution, so we can put it straight in there and start to report off the top of that data. We can also go into elastic search to allow us to be able to query the data and then the last one on the list here is kind of interesting. It's nothing to do with machine learning as such, so we don't have to worry about it but Splunk Splunk is actually a third party tool. It's nothing to do with AWS as such other than the two companies seem to get on quite well and AWS have configured Amazon Kinesis Data Firehose to be able to send data straight into a Splunk end point if you've got one. Splunk is then used for sort of data analysis and reporting, and it's used a lot of the time by technical teams who want to do things like SIEM security incident, event management and that type of thing. So if you have Splunk enterprise than you can stream all of your data through Kinesis Data Firehose straight into that and then that leaves finally, the last one in the family to talk about, which is Amazon Kinesis Data Analytics. Now that has Data Analytics in the name, but it's not there to produce graphs and to make things look pretty pretty. It's not a business intelligence tool, so it's not taking the place of or even competing against Amazon Quicksight. This is the ability to run at scale SQL commands, SQL Transforms, Java Applications, Java Transforms to analyze data that's coming in on the fly that's coming in via Kinesis stream or a firehose so we can send the data from Kinesis data streams or from firehose into this managed environment, which can run code for us to be able to analyze that data Again, it's not producing the grafts per se. It's producing the data behind it that then a subsequent step a subsequent process in our system can take that data and do something with it. So this actually might be how we want to do a shopping cart recommendation engine, for example, for a website is taking all the data from the click stream data from our website putting into Kinesis data streams now that can then be used for a number of different things. One of them could be to send it into the Kinesis data analytics that can on the fly, look to see what users are doing. Respond to events of sale information and trends in buying certain products and then feed that back to the website. Not so much a machine learning topic, but Amazon Kinesis Data Analytics can provide that transformation of data as well that we can use to send that on into a machine learning model. So there are a number of different ways that, in Amazon Web Services we can transform data in an appropriate way for our machine learning and it depends on the scale of data and the speed of the data as to which one you'd want to use. If it's something you already have and it's sat in an S3 bucket somewhere, then let's use Glue and Athena to go and query that data. Put it into a different view and make it available for a machine learning backend. If we're dealing with data, that's in multiple different locations like DynamoDB and S3 and maybe a couple of different S3 locations. Then again, we can use Glue with its ETL ability extract, transform load and we can do that and bring in that way. If we've got data that's flying in at a rate of knots then maybe we want to use Amazon Kinesis and kinesis data streams along with Kinesis Data Analytics to be able to transform that data, take it out of data analytics and maybe put it into S3 from there and then train or model in for using our model with that data. If we have a very, very large data set as opposed to a fast streaming data set, then let's use EMR the elastic map reduce service and use that to churn through the data and perform a version of ETL itself that you can then pass on to a machine learning model and we'll look at EMR in more detail in a subsequent lesson. So let's have a look at a couple of architectures where Kinesis plays a key role and here is a blend of a few services that I was just talking about. So we have on the left hand side IOT Internet of things. So this is really a cloud of hundreds of thousands of sensors all taking very simple many measurements, but streaming them all at a single endpoint definition which happens to be Amazon Kinesis Data Streams, so it is able to scale out to be able to accept all of that traffic coming in. I think about it. If this was one EC2 instance then our instance is going to be completely overwhelmed by just the sheer number of connections coming in, let alone the amount of data coming in. So Kinesis Data Streams is the service which can scale to accept all of that information in. Then what's it going to do with it? Where's it going to send it? Well, one place it can send it is into EMR. So, EMR is this massive parallel computing environment which can process this data and in this sense, we're using essentially is an ETL product, but a massive ETL product to be out to churn through all that data and then we can persist that data in S3 we're nice and decoupled. We can come and use that for inference or for training later on. Let's have a look at another diagram here, and this one absolutely has come up in the exam before and it's what I was mentioning before about Amazon Rekognition video but this time I've sort of completed the diagram and made it a little bit more of an end to end solution. So here at the top left, we have our video cameras. This is a surveillance video camera and this is sending video data onto the network and we have configured it potentially with software inside of itself or from a video streaming service somewhere to send that data into Amazon Kinesis video streams. So this is a way that we can just can figure an endpoint to be able to accept that special, if you like, kind of streaming data that isn't as straightforward in a simple it's just some temperature telemetry coming of of an IOT device. This is now fully compressed video stream coming in from of webcam. We have very little control of the actual internals of how it actually works and so that streaming video comes in and it is configured to send that data directly onto Amazon Rekognition video. We've looked at this service before. It is a fully managed service from AWS. All it does is watch that video stream and we can configure it to do a number of different analyses on that stream, one of them being facial recognition. So can you see the face that we're looking for in this live video stream? So this is a surveillance type of activity. Now, if it can, what's it going to do with that data? Or if it can't, what's it going to do with the data saying that it currently can't? Well we didn't talk about that so much before, but what Amazon Rekognition Video will do is send that data out so it's no longer a picture or video data. It's now just this textual data of like what I can see the coordinates in the frame. What frame number? What face? Who do I think this is? It would send all of this data out to Amazon Kinesis data streams. Because again, we're talking about a lot of data and we need to be able to decouple the production of that data from the processing of that data and we can do that through Amazon Kinesis data streams and then hook that into In this case, we hooked into AWS Lambda. So a very scalable serverless compute platform, all we have to do is write a very simple function in Lambda. It can then be triggered by the Kinesis data stream and it could say, for example, send an SMS notification through Amazon Web Services SNS so Simple Notification Service is can send out short message service SMS to someone's mobile to say, Hey, we've spotted that person we're looking for in this crowd of people Go and take action and let's assume that the that's a good thing they've won a prize. They've won a competition and they're going to be rewarded justly. So that's Amazon Kinesis. There's a whole suite of those four different services in there, so it's a family of services and predominantly it's about dealing with the ingestion of large scale data, and we're talking large in AWS terms, we're talking really, really large.